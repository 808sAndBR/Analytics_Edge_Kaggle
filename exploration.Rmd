---
title: "Kaggle"
author: "Scott Brenstuhl"
date: "May 29, 2016"
output: html_document
---


```{r, echo = FALSE}
# setwd("/Users/scottbrenstuhl/Projects/AnalyticsEdge/Analytics_Edge_Kaggle/")

library(caret)
library(doMC)
library(dplyr)
library(ggplot2)
library(mice)
library(randomForest)
library(readr)
library(rpart)
library(rpart.plot)

registerDoMC(cores = 4)

training <- read.csv("data/train2016.csv", na.strings = c("NA",""))
testing <- read.csv("data/test2016.csv", na.strings = c("NA",""))
```


# Exploration
```{r, echo=FALSE}
str(training)

# Commented out to avoid Rmd error
#View(head(training,10))

prop.table(table(complete.cases(training)))

# No overlap in user_ids to exploit 
table(testing$USER_ID %in% training$USER_ID)
```

Very low percent of respondednts answered all questions so I will probably need
to figure out some good impution strategies.


```{r, echo=FALSE}

CART <- rpart(Party ~.-USER_ID, data = training, method = "class")
prp(CART)

CART_pred <- predict(CART, newdata = testing, type = "class")

CART_submission <- data.frame(USER_ID = testing$USER_ID, 
                              Predictions = CART_pred)

write.csv(CART_submission, "submissions/BasicCART.csv", row.names=FALSE)

```

```{r, echo=FALSE}
# Make data sets considering NA a choice of no response

removeNA <- function(x){
    if(is.factor(x) & sum(is.na(x)) > 0){
        factor(as.character(x), levels = c(levels(x), "noResponse"))
    }else{
            x
        }
    }

trainNoAns <- as.data.frame(lapply(training, removeNA))
testNoAns <- as.data.frame(lapply(testing, removeNA))


trainNoAns[,-2][is.na(trainNoAns[,-2])] <- "noResponse"
testNoAns[,-2][is.na(testNoAns[,-2])] <- "noResponse"

avg_YOB <-round(mean(na.omit(trainNoAns$YOB)))

trainNoAns$YOB[is.na(trainNoAns$YOB)] <- avg_YOB
testNoAns$YOB[is.na(testNoAns$YOB)] <- avg_YOB

table(trainNoAns$YOB)
```

I should make 2039 be 1939

```{r, echo=FALSE}
noRespCART <- rpart(Party ~.-USER_ID, data = training, method = "class")

# These are the same so no point in predicting off this one
prp(noRespCART)
prp(CART)


# Lets try random forest instead though since we got rid of those pesky NAs
set.seed(1809)
noResp_RF <-train(Party ~.-USER_ID, data = trainNoAns, method = "rf",
                trControl = trainControl(method="cv", number=5),
                prox=TRUE, allowParallel=TRUE)

print(noResp_RF)
print(noResp_RF$finalModel)

varImp(noResp_RF)

noResp_RF_pred <- predict.train(noResp_RF, newdata = testNoAns)

noResp_submission <- data.frame(USER_ID = testing$USER_ID, 
                              Predictions = noResp_RF_pred)

write.csv(noResp_submission, "submissions/NoResp_RF.csv", row.names=FALSE)

```


```{r, echo = FALSE}

percent_missing <- function(column){
        col_table <- prop.table(table(column, useNA = "always"))
        as.numeric(col_table[is.na(names(col_table))])
    }

ans_missing <- lapply(training, percent_missing) 
ans_missing <- data_frame(qustion = names(ans_missing),
                          perc_missing = as.numeric(ans_missing))


qplot(qustion, y=perc_missing, data = subset(ans_missing, perc_missing >.45 ))
qplot(qustion, y=perc_missing, data = subset(ans_missing, perc_missing <.30 ))
qplot(qustion, y=perc_missing, data = subset(ans_missing, perc_missing >.30 &
                                                 perc_missing <.45 ))
```

Q124742 is missing a lot more responses than the rest so it will probably be
best to remove it.

Only the non-question (demagraphics) have less than 30% missing which isn't too
surprising.

```{r, echo = FALSE}
# Not so helpful but want to remember it for now
#md.pattern(training)

# This might be better to do after deciding which columns to use?
missing_perc <- apply(is.na(training),1,function(x) sum(x)/108)
table(round(missing_perc, digits = 1))
prop.table(table(missing_perc >.5))

dim(training)

```


```{r echo = FALSE}
training$Training <- 1
testing$Training <- 0

all_data <- rbind(training[names(training) != "Party"], testing)

# Looks like it worked
dim(training)
dim(testing)
dim(all_data)
summary(all_data)

imputed_all <- complete(mice(all_data[names(all_data) != 
                                          c("USER_ID", "Training")]))

write.csv(imputed_all, "data/imputed_all.csv", row.names=FALSE)
dim(training)

training$Training <- NULL
testing$Training <- NULL

imp_train <- cbind(USER_ID = training$USER_ID, 
                   Party = training$Party, 
                   imputed_all[1:5568,])
imp_test <- cbind(USER_ID = testing$USER_ID, imputed_all[5569:nrow(imputed_all),])

```

```{r, echo=FALSE}
imp_CART <- rpart(Party ~.-USER_ID, data = imp_train, method = "class")

# still the same but people get sorted better with data imputed 
prp(CART)
prp(imp_CART)

imp_CART_pred <- predict(imp_CART, newdata = testing, type = "class")

imp_CART_submission <- data.frame(USER_ID = testing$USER_ID, 
                              Predictions = imp_CART_pred)

write.csv(imp_CART_submission, "submissions/ImpCART.csv", row.names=FALSE)

```

```{r, echo = FALSE}

set.seed(1809)
imp_RF <-train(Party ~.-USER_ID, data = imp_train, method = "rf",
                trControl = trainControl(method="cv", number=5),
                prox=TRUE, allowParallel=TRUE)

print(imp_RF)
print(imp_RF$finalModel)

imp_RF_pred <- predict.train(imp_RF, newdata = imp_test)

impRF_submission <- data.frame(USER_ID = testing$USER_ID, 
                              Predictions = imp_RF_pred)

write.csv(impRF_submission, "submissions/Imp_RF.csv", row.names=FALSE)

```


```{r, echo = FALSE}
# I want to replace all NA with 0 Positive with 1 and negative with -1

#since the first facor level is No when yes/no lets make it negative
sapply(training, function(x) levels(x)[1])

train_num <- training
test_num <- testing

# Get it to stop yelling at me about factors
train_num[grepl("^Q" , names(train_num))] <- lapply(
    train_num[grepl("^Q" , names(train_num))],
    as.character)

# Change strings to numbers then changes NA to 0
numericizer <- function(column) {
    lev1 <- levels(column)[1]
    column <- as.character(column)
    column <- ifelse(column == lev1, -1, 1)
    column[is.na(column)] <- 0
    column
}

train_num[grepl("^Q" , names(train_num))] <- lapply(train_num[grepl("^Q" , names(train_num))], numericizer)
test_num[grepl("^Q" , names(test_num))] <- lapply(test_num[grepl("^Q" , names(test_num))], numericizer)
```

```{r, echo = FALSE}



```


```{r, echo = FALSE}

baseGLM <- glm(Party~.-USER_ID, training, family = binomial)
summary(baseGLM)

noAnsGLM <- glm(Party~.-USER_ID, trainNoAns, family = binomial)
summary(noAnsGLM)

class(training$YOB)
class(trainNoAns$YOB)
```


```{r, echo=FALSE, cache= TRUE}

noAnsRF <- rf(Party~.-USER_ID , data = trainNoAns)

```

## Todo

Control for YOB (scale)
Reapply previous things 

```{r results table, echo=FALSE}
c("CART", 0.61207, "Basic CART without doing anything to the data.")
c("noResp_RF", 0.62069, "Random Forest with NA = noResponse and NA YOB = mean YOB")
c("imp_CART", 0.63649)
c("imp_RF",0.62069)

```


